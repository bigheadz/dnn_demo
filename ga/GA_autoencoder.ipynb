{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def getCsvDf(readFunc=None):\n",
    "    def read_csv(path):\n",
    "        if readFunc:\n",
    "            return readFunc(path)\n",
    "        else:\n",
    "            return pd.read_csv(path, index_col=0)\n",
    "    \n",
    "    class CsvDf:\n",
    "        \"\"\"\n",
    "        创建一个存储于csv的表格， 封装了表格的读取， 删除， 存档， 并且支持对表格的指定行， 进行md5码存储后， 作为index， 方便后续查询\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, fileName, path=\".\"):\n",
    "            self.path = path\n",
    "            self.fileName = fileName\n",
    "            self.df = None\n",
    "\n",
    "        def get_df(self):\n",
    "            if self.df is None:\n",
    "                self.df = self.read()\n",
    "\n",
    "            if self.df is None:\n",
    "                self.df = pd.DataFrame()\n",
    "\n",
    "            return self.df\n",
    "\n",
    "        def read(self):\n",
    "            if os.path.exists(os.path.join(self.path, self.fileName)):\n",
    "#                 print(\"read from csv\", os.path.join(self.path, self.fileName))\n",
    "                return readFunc(os.path.join(self.path, self.fileName))\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "        def save(self, new_history):\n",
    "#             print(\"保存\", os.path.join(self.path, self.fileName))\n",
    "            new_history.to_csv(os.path.join(self.path, self.fileName))\n",
    "            self.df = new_history\n",
    "            return self.df\n",
    "\n",
    "        def clear(self):\n",
    "            if os.path.exists(os.path.join(self.path, self.fileName)):\n",
    "                os.remove(os.path.join(self.path, self.fileName))\n",
    "            self.df = pd.DataFrame()\n",
    "        \n",
    "    return CsvDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#KDense\n",
    "from keras.layers import Dense, Activation, Input, BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "def direct_pip(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "act_table = {\n",
    "    0: None,\n",
    "    1: 'relu',\n",
    "    2: 'sigmoid',\n",
    "    3: 'tanh',\n",
    "    4: 'softmax'\n",
    "}\n",
    "\n",
    "batch_norm_table = {\n",
    "    0: None,\n",
    "    1: BatchNormalization\n",
    "}\n",
    "\n",
    "def make_dense(inputs, layer, act, norm, _debug_layer=False):\n",
    "    if _debug_layer:\n",
    "        print(\"make layer from {} {} {}\".format(layer, act, norm))\n",
    "    layer = int(layer)\n",
    "    act = int(act)\n",
    "    norm = int(norm)\n",
    "    \n",
    "    if layer <= 0:\n",
    "        return inputs\n",
    "    dense = Dense(layer)(inputs)\n",
    "    if _debug_layer:\n",
    "        print(dense)\n",
    "    norm = get_norm(norm)(dense)\n",
    "    if _debug_layer:\n",
    "        print(norm)\n",
    "    act = get_act(act)(norm)\n",
    "    if _debug_layer:\n",
    "        print(act)\n",
    "    return act\n",
    "\n",
    "\n",
    "def get_norm(code):\n",
    "    norm = batch_norm_table[code]\n",
    "    if norm is None:\n",
    "        return direct_pip\n",
    "    else:\n",
    "        return norm()\n",
    "\n",
    "\n",
    "def get_act(code):\n",
    "    act = act_table[code]\n",
    "    if act is None:\n",
    "        return direct_pip\n",
    "    else:\n",
    "        return Activation(act)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DenseDNAs import DenseDNAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Model #泛型模型  \n",
    "from keras.layers import Dense, Input  \n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "from DNA import IDNA\n",
    "\n",
    "inputs = Input(shape=(1,))\n",
    "\n",
    "x = np.linspace(0, 1, 256)\n",
    "y = x ** 2 + x * 0.11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load NNDNAs.py\n",
    "from DNA import IDNA, match\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from DenseDNAs import DenseDNAs\n",
    "\n",
    "def _read_rna_history(path):\n",
    "    pf = pd.read_csv(path, index_col=0, header=[0, 1])\n",
    "    return pf.astype(np.float64) #转换成64是为了后续和nan合并的时候， 数据类型一致\n",
    "\n",
    "def NNDNAs(model_maker, train_model, fitness_params):\n",
    "    class _NNDNAs(IDNA):\n",
    "        \"\"\"\n",
    "        构成普通的NN， 或者DNN的网络结构\n",
    "        其核心提供了对DNA进行操作的方法， 和一些基因算法中的超参数的设置和修改\n",
    "        \"\"\"\n",
    "        def __init__(self, target_name, max_layer_n,n_mean_stds=None, denseDNAs=None):\n",
    "            self.denseDNAs = denseDNAs if denseDNAs else [DenseDNAs(model_maker)() for _ in range(max_layer_n)]\n",
    "            self.max_layer_n = max_layer_n\n",
    "            self.n_mean_stds = n_mean_stds if n_mean_stds else [(10, 2) for _ in range(self.max_layer_n)]\n",
    "            self.target_name = target_name\n",
    "            self.rna_csv = getCsvDf(_read_rna_history)(\"{}_rna_fitness.csv\".format(target_name))\n",
    "\n",
    "        def create(self, max_pop_n=20):\n",
    "            \"\"\"\n",
    "            :param n_mean_stds: 每一层的初始化的（均值， 方差)\n",
    "            :return:返回所有的DNA的pandas列表， 每一行一个DNA， 对应一个层\n",
    "            \"\"\"\n",
    "            dnas_list = [self.denseDNAs[i].create(num=max_pop_n, n_mean_std=self.n_mean_stds[i]) for i in\n",
    "                         range(self.max_layer_n)]\n",
    "\n",
    "            return pd.concat(dnas_list, axis=1, keys=self.get_dna_columns())\n",
    "\n",
    "        def evolve(self, dnas, fitness):\n",
    "            \"\"\"\n",
    "            优胜劣汰， 变异， 包括了有性生殖\"\n",
    "            :param dnas:  重要的是， dnas是一个下层dnas的列表， 列表的元素是某个结构的dnas\n",
    "            :param fitness:\n",
    "            :return:\n",
    "            \"\"\"\n",
    "            # fitness转换成排名计分\n",
    "            fitness = fitness.value #TODO: 目前只是使用一个评判标准， 就是原始的-1 * loss\n",
    "            fitness = fitness.rank()\n",
    "            fitness += 1  # 避免排位很低的， 一点机会都没有\n",
    "            #TODO 现在排位的方式， 不利于在复杂的情况下寻找最优解， 因为当有20个结果差不多的fitness出现的时候，\n",
    "            # 他们结构的差异化较大， 理想结果是， 让他们都产生变异， 而不是只让头部的几个结果生存下来。\n",
    "            dnas['fitness'] = fitness\n",
    "\n",
    "            # 优胜劣汰\n",
    "            surviors = dnas.sample(frac=0.2, weights=dnas.fitness)\n",
    "\n",
    "            # 有性生殖\n",
    "            father = dnas.sample(frac=0.3, weights=dnas.fitness)\n",
    "            mother = dnas.sample(frac=0.4, weights=dnas.fitness)\n",
    "            father, mother = match(father, mother, childsize=int(len(fitness) * 0.8), father_weight=father.fitness,\n",
    "                                   mother_weight=mother.fitness)\n",
    "\n",
    "            children = self.sex_propagation(father, mother)\n",
    "            dnas = surviors.append(children).reset_index(drop=True)\n",
    "            \n",
    "            #变异\n",
    "            dnas = self.mutate(dnas)\n",
    "            \n",
    "            #保存到磁盘\n",
    "            self.save_dnas(dnas)\n",
    "            return dnas\n",
    "        \n",
    "        def save_dnas(self, dnas):\n",
    "            dnas.to_csv(\"{}_dnas.csv\".format(self.target_name))\n",
    "\n",
    "        def load_dnas(self):\n",
    "            return pd.read_csv(\"{}_dnas.csv\".format(self.target_name), index_col=0,  header=[0, 1])\n",
    "        \n",
    "        def mutate(self, dnas):\n",
    "            \"\"\"\n",
    "            变异\n",
    "            :param dnas:\n",
    "            :return: 变异后的dnas列表\n",
    "            \"\"\"\n",
    "            dnas = [self.denseDNAs[i].mutate(dnas.loc[:, \"layer{}\".format(i)].copy()) for i in range(self.max_layer_n)]\n",
    "            return pd.concat(dnas, axis=1, keys=self.get_dna_columns())\n",
    "\n",
    "        def to_RNA(self, dna):\n",
    "            def nans(shape, dtype=float):\n",
    "                a = np.empty(shape, dtype)\n",
    "                a.fill(np.nan)\n",
    "                return a\n",
    "\n",
    "            \"\"\"翻译成RNA， RNA是可以表达， 并且也可以被保存的\"\"\"\n",
    "            rna = [self.denseDNAs[i].to_RNA(dna[\"layer{}\".format(i)]) for i in range(self.max_layer_n)]\n",
    "            rna = pd.concat(rna, axis=1, keys=self.get_dna_columns())\n",
    "\n",
    "            # 压缩rna, 避免因为0 10 10和10 0 10 而出现的两次重复的计算, 实际压缩就是把类似 [nan, 1, nan, 2, 3] 变成 [1, 2, 3, nan, nan]\n",
    "            _nans = nans(rna.shape[1])\n",
    "            rna = rna.apply(lambda row: np.hstack([row.dropna().values, _nans])[:rna.shape[1]], axis=1)\n",
    "            return rna\n",
    "\n",
    "        def to_model(self, rna_row, inputs):\n",
    "            model = inputs\n",
    "            for i in range(self.max_layer_n):\n",
    "                model = self.denseDNAs[i].to_dense(rna_row[\"layer{}\".format(i)], model)\n",
    "            return model\n",
    "        \n",
    "        def do_cal_fitness(self, row, inputs):\n",
    "            row = row.fillna(0)\n",
    "            model = self.to_model(row, inputs)\n",
    "            fitness = train_model(model)\n",
    "            for key in fitness:\n",
    "#                 print(key, fitness[key])\n",
    "                row[\"fitness\", key] = fitness[key]\n",
    "            return row\n",
    "    \n",
    "        def update_history(self, update_method):\n",
    "            rna_fitness_history = self.rna_csv.get_df()\n",
    "            rna_fitness_history = update_method(rna_fitness_history)\n",
    "            return self.rna_csv.save(rna_fitness_history)\n",
    "        \n",
    "        def get_fitness(self, df_rna, inputs):\n",
    "            \"\"\"\n",
    "            如果有历史数据， 就从历史数据中获取， 如果没有， 就计算结果， 并把结果合并到历史数据中\n",
    "            \"\"\"\n",
    "            df_rna = pd.concat([df_rna, pd.DataFrame(index=df_rna.index,\n",
    "                                                     columns=pd.MultiIndex.from_product([[\"fitness\"], fitness_params]))], axis=1)\n",
    "            df_rna = df_rna.astype(np.float64)\n",
    "            \n",
    "            # 获取历史\n",
    "            rna_fitness_history = self.rna_csv.get_df()\n",
    "            if rna_fitness_history.empty:\n",
    "                rna_fitness_history = pd.DataFrame(columns=df_rna.columns)\n",
    "            \n",
    "            # 如果有历史数据， 就从历史数据中merge结果， 如果没有， 再计算\n",
    "            df_rna = pd.merge(df_rna.iloc[:, 0:-len(df_rna.fitness.columns)], \n",
    "                              rna_fitness_history, how='left', on=df_rna.columns[0:-len(df_rna.fitness.columns)].tolist())\n",
    "            # 显式的指定df_rna值的类型， 不然的话， 和带有nan的组合并的时候， 结果会失败\n",
    "            df_rna = df_rna.astype(np.float64)\n",
    "            \n",
    "            # 需要计算的数据\n",
    "            df_rna_cal = df_rna[np.isnan(df_rna.fitness.value)].drop_duplicates()\n",
    "            \n",
    "            # 一行一行的计算结果\n",
    "            # 应该有个单独保存计算结果的地方， 因为这个可能也是非常耗费时间的， 一次计算非常耗费时间\n",
    "            def save_row(row):\n",
    "                rna_fitness_history = rna_fitness_history.append(row, ignore_index=True)\n",
    "                rna_fitness_history = self.rna_csv.save(rna_fitness_history)\n",
    "            \n",
    "            df_rna_result = pd.DataFrame(columns=df_rna_cal.columns)\n",
    "            for _, row in df_rna_cal.iterrows():\n",
    "                row = self.do_cal_fitness(row, inputs)\n",
    "                df_rna_result = df_rna_result.append(row)\n",
    "                rna_fitness_history = rna_fitness_history.append(row, ignore_index=True)\n",
    "                rna_fitness_history = self.rna_csv.save(rna_fitness_history)\n",
    "                \n",
    "            df_rna_cal = df_rna_result\n",
    "#             print(\"get_fitness>df_rna_cal------------------\\n\", df_rna_cal)\n",
    "            # 把结果数据合并回到df_rna\n",
    "#             print(\"get_fitness>df_rna------------------\\n\", df_rna)\n",
    "            df_rna = pd.merge(df_rna,\n",
    "                              df_rna_cal,\n",
    "                              how='left',\n",
    "                              on=df_rna.columns[0:-len(df_rna.fitness.columns)].tolist()\n",
    "                             ).fillna(0)\n",
    "#             print(\"get_fitness>df_rna------------------\\n\", df_rna)\n",
    "            merge_fitness = df_rna.fitness_x + df_rna.fitness_y\n",
    "#             print(\"get_fitness>merge_fitness------------------\\n\", merge_fitness)\n",
    "            merge_fitness = pd.DataFrame(merge_fitness.values, \n",
    "                                         index=df_rna.index, \n",
    "                                         columns=pd.MultiIndex.from_product([[\"fitness\"], merge_fitness.columns.tolist()])\n",
    "                                        )\n",
    "#             print(\"get_fitness>merge_fitness------------------\\n\", merge_fitness)\n",
    "            df_rna = pd.concat([df_rna.iloc[:, :-2*len(rna_fitness_history.fitness.columns)], merge_fitness],\n",
    "                               axis=1)\n",
    "#             print(\"get_fitness>df_rna------------------\\n\", df_rna)\n",
    "            return df_rna.fitness\n",
    "\n",
    "        def sex_propagation(self, father, mother):\n",
    "            # 用denseDNA对每个Dense进行sex_propagation\n",
    "            children = [\n",
    "                self.denseDNAs[i].sex_propagation(father.loc[:, \"layer{}\".format(i)],\n",
    "                                                  mother.loc[:, \"layer{}\".format(i)])\n",
    "                for i in range(self.max_layer_n)]\n",
    "            return pd.concat(children, axis=1, keys=self.get_dna_columns())\n",
    "\n",
    "        def get_dna_columns(self):\n",
    "            return [\"layer{}\".format(i) for i in range(self.max_layer_n)]\n",
    "\n",
    "    return _NNDNAs\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     nnDNAs = NNDNAs(print)(5)\n",
    "#     dnas = nnDNAs.create()\n",
    "#     print(dnas)\n",
    "#     # dnas = nnDNAs.evolve(dnas, fitness)\n",
    "#     for i in range(5):\n",
    "#         dnas = nnDNAs.evolve(dnas, nnDNAs.get_fitness(nnDNAs.to_RNA(dnas)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update over\n",
      "0th: max=0.8999877547562731 top 3 mean:0.8999792794219131\n",
      "1th: max=0.8999732397783113 top 3 mean:0.8999417420591126\n",
      "2th: max=0.9025602396177899 top 3 mean:0.9008483528569565\n",
      "3th: max=0.9231218897475812 top 3 mean:0.913090612522272\n",
      "4th: max=0.9592016492891315 top 3 mean:0.9388815559447409\n",
      "5th: max=0.906757604458172 top 3 mean:0.9041358752360441\n",
      "6th: max=0.9176515157731023 top 3 mean:0.9110941469875442\n",
      "7th: max=0.954031674220027 top 3 mean:0.9262762766874143\n",
      "8th: max=0.9497629608614921 top 3 mean:0.6157095734349377\n",
      "9th: max=0.9004457773400815 top 3 mean:0.6001490485370141\n",
      "10th: max=0.8999853650867135 top 3 mean:0.8997492569330046\n"
     ]
    }
   ],
   "source": [
    "def train_model(model):\n",
    "    ouput = Dense(1)(model)\n",
    "    model = Model(inputs=inputs, outputs=ouput) #暂时使用这个来计算结果\n",
    "    model.compile(loss='mse', optimizer='adam') # TODO: 这个应该根据最后一个激活函数的类型来进行选择， loss\n",
    "    params = model.count_params()\n",
    "    cost = cal_net_cost(params)\n",
    "    train_history = model.fit(x, y, epochs=50, batch_size=64, verbose=0)\n",
    "    #这个取值也过于粗糙，其实应该考虑收敛速度， 收敛的平滑程度等等的， 还包括了， 可能出现的初始参数导致不收敛的情况\n",
    "    loss = train_history.history['loss'] # loss > 0, 归一化处理后， 一般小于1\n",
    "    min_loss = np.min(np.array(loss))\n",
    "    #映射到0~1之间， 越小， fitness越逼近1， 变化较大； 越大越逼近0， 变化减小\n",
    "    fitness = -2 / (1 + (np.e ** (-min_loss))) + 2\n",
    "    fitness = fitness * (1 - 0.1 * cost) # 使用fitness的10之一作为cost的代价， 当loss差不多的时候， cost就会发挥作用\n",
    "    return {\"value\": fitness, \"loss\": min_loss, \"params\": params}\n",
    "\n",
    "def _cal_fitness(loss, params):\n",
    "#     print(\"_cal_fitness\", loss, params)\n",
    "    cost = cal_net_cost(params)\n",
    "    fitness = -2 / (1 + (np.e ** (-loss))) + 2\n",
    "    fitness = fitness - 0.1 * cost\n",
    "#     print(\"_cal_fitness\", fitness)\n",
    "    return fitness\n",
    "\n",
    "def cal_rna_fitness(rna_history):\n",
    "    # 或许， 应该用矩阵的方式来操作， 但是这样， 计算fitness的代码就变成了两块， 考虑到不是经常调整参数， \n",
    "    # 就暂时先不弄这个, 或者values就该最后一起计算， 而不是分开计算\n",
    "    _rna_h = rna_history.copy()\n",
    "    values = _rna_h.fitness.apply(lambda fitness: _cal_fitness(fitness.loss, fitness.params), axis=1)\n",
    "    _rna_h[\"fitness\", \"value\"] = values\n",
    "    return _rna_h\n",
    "\n",
    "def cal_net_cost(params):\n",
    "    \"\"\"\n",
    "    计算网络的复杂程度， 如果网络越复杂， 就应该给予一些惩罚， 而越简单的网络，得到更好的奖励\n",
    "    \"\"\"\n",
    "    # TODO: 现在是最简单的方式, 先简单的计算参数的多少， 而且只是实用与DNN, 有个好处是， 结果可以复现， 而不会因为机器当时的训练数据收到变化\n",
    "    # 映射到 0~1之间， 1000为超参数， 当params， 位于0~4k的时候， 值变化较线性， 超过4k，变化会减缓\n",
    "    cost =  2 / (1 + (np.e ** (-params / 1000))) - 1\n",
    "    return cost\n",
    "\n",
    "\n",
    "# 这个score不能和fitness聪明， 不然， fitness.fitness合并的时候， 下层的fitness也会被加上_x, _y\n",
    "# 这个算是pandas的bug吧\n",
    "nnDNAs = NNDNAs(make_dense, train_model, [\"value\", \"loss\", \"params\"])(\"linear_test\", 3)\n",
    "dnas = nnDNAs.create(10)\n",
    "# dnas = nnDNAs.load_dnas()\n",
    "nnDNAs.update_history(cal_rna_fitness)\n",
    "print(\"update over\")\n",
    "for i in range(20):\n",
    "    fitness = nnDNAs.get_fitness(nnDNAs.to_RNA(dnas), inputs)\n",
    "    #输出必要的fitness信息， 以供参考\n",
    "    print(\"{}th: max={} top 3 mean:{}\".format(i, fitness.value.max(), np.mean(fitness.value.sort_values(ascending=False)[:3])))\n",
    "    dnas = nnDNAs.evolve(dnas, fitness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat ./linear_test_rna_fitness.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f ./linear_test_rna_fitness.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.datasets import mnist  \n",
    "from keras.models import Model #泛型模型  \n",
    "from keras.layers import Dense, Input  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#制造数据\n",
    "x = np.linspace(0, 1, 256)\n",
    "y = x ** 2 + x * 0.11\n",
    "\n",
    "#简单的网络\n",
    "inputs = Input(shape=(1,))\n",
    "layer = Dense(32)(inputs)\n",
    "# layer = Dense(32, activation='relu')(layer)\n",
    "# layer = Dense(32, activation='relu')(layer)\n",
    "layer = Dense(1, activation='relu')(layer)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=layer)\n",
    "model.compile(loss='mse', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = model.fit(x, y, batch_size=32, epochs=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.plot(x, predict)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_history.history['loss'])\n",
    "plt.show()\n",
    "# 我们想法把结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 优化代码， 让代码更具有普适性\n",
    "# 优化rank的算法， 避免一个网络通吃的情况\n",
    "# 加上网络结构和网络速度的loss计算\n",
    "# 还有很多事情要做， 首先第一步就是， 随机搜寻数据， 当数据的计算速度较慢的时候， 整个算法的寻址速度太慢了， 是不是应该引入更多的规则或者什么trick\n",
    "# 需要做的事情\n",
    "1. 随机搜寻最优解， 当计算一次很慢的时候， 是否应该引入更多的trick，或者人工干预\n",
    "2. 加入更多的监控， 能让我们知道当前网络的状态\n",
    "3. 加入更多的人工干预， 并且及时生效的机制， 让我们知道， 网络是否可用\n",
    "4. 针对已有的网络， 对网络中已经比较好的结果， 进行细调整的方式， 比如我固住前后几层的参数， 看是否能够， 把其中部分参数给去掉， 类似于减枝的操作， 让我们的网络更加快速"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
